{"cells":[{"cell_type":"markdown","metadata":{"id":"9Gtvymap9cXw"},"source":["# 2.1 크롤링"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zj7BV1W-9gy_"},"outputs":[],"source":["!pip install beautifulsoup4==4.6.0\n","!requests==2.25.1\n","!requests-oauthlib==1.3.0"]},{"cell_type":"markdown","metadata":{"id":"Hd2lN4Tq9cX4"},"source":["[크롤링]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"EHYAGtre9cX5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sleep 90seconds. Count:584280,  Local Time:2022-05-31 07:20:04,  Data Length:0\n","Sleep 90seconds. Count:584340,  Local Time:2022-05-31 07:22:51,  Data Length:0\n","Sleep 90seconds. Count:584400,  Local Time:2022-05-31 07:25:38,  Data Length:0\n","Sleep 90seconds. Count:584460,  Local Time:2022-05-31 07:28:24,  Data Length:0\n","Sleep 90seconds. Count:584520,  Local Time:2022-05-31 07:31:11,  Data Length:0\n","Sleep 90seconds. Count:584580,  Local Time:2022-05-31 07:33:58,  Data Length:0\n","Sleep 90seconds. Count:584640,  Local Time:2022-05-31 07:36:44,  Data Length:0\n","Sleep 90seconds. Count:584700,  Local Time:2022-05-31 07:39:30,  Data Length:0\n","Sleep 90seconds. Count:584760,  Local Time:2022-05-31 07:42:17,  Data Length:0\n","Sleep 90seconds. Count:584820,  Local Time:2022-05-31 07:45:03,  Data Length:0\n","Sleep 90seconds. Count:584880,  Local Time:2022-05-31 07:47:50,  Data Length:0\n","Sleep 90seconds. Count:584940,  Local Time:2022-05-31 07:50:37,  Data Length:0\n","Sleep 90seconds. Count:585000,  Local Time:2022-05-31 07:53:23,  Data Length:0\n","Sleep 90seconds. Count:585060,  Local Time:2022-05-31 07:56:10,  Data Length:0\n","Sleep 90seconds. Count:585120,  Local Time:2022-05-31 07:58:56,  Data Length:0\n","Sleep 90seconds. Count:585180,  Local Time:2022-05-31 08:01:43,  Data Length:0\n","Sleep 90seconds. Count:585240,  Local Time:2022-05-31 08:04:30,  Data Length:0\n","Sleep 90seconds. Count:585300,  Local Time:2022-05-31 08:07:17,  Data Length:0\n","Sleep 90seconds. Count:585360,  Local Time:2022-05-31 08:10:04,  Data Length:0\n","Sleep 90seconds. Count:585420,  Local Time:2022-05-31 08:12:51,  Data Length:0\n","Sleep 90seconds. Count:585480,  Local Time:2022-05-31 08:15:37,  Data Length:0\n","Sleep 90seconds. Count:585540,  Local Time:2022-05-31 08:18:24,  Data Length:0\n","Sleep 90seconds. Count:585600,  Local Time:2022-05-31 08:21:10,  Data Length:0\n","Sleep 90seconds. Count:585660,  Local Time:2022-05-31 08:23:57,  Data Length:0\n","Sleep 90seconds. Count:585720,  Local Time:2022-05-31 08:26:43,  Data Length:0\n","Sleep 90seconds. Count:585780,  Local Time:2022-05-31 08:29:30,  Data Length:0\n","Sleep 90seconds. Count:585840,  Local Time:2022-05-31 08:32:17,  Data Length:0\n","Sleep 90seconds. Count:585900,  Local Time:2022-05-31 08:35:03,  Data Length:0\n","Sleep 90seconds. Count:585960,  Local Time:2022-05-31 08:37:56,  Data Length:0\n","Sleep 90seconds. Count:586020,  Local Time:2022-05-31 08:40:42,  Data Length:0\n","Sleep 90seconds. Count:586080,  Local Time:2022-05-31 08:43:29,  Data Length:0\n","Sleep 90seconds. Count:586140,  Local Time:2022-05-31 08:46:16,  Data Length:0\n","Sleep 90seconds. Count:586200,  Local Time:2022-05-31 08:49:03,  Data Length:0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import requests\n","from bs4 import BeautifulSoup \n","import time\n","\n","\n","result = pd.DataFrame()                                    \n","\n","for i in range(584274, 595226):\n","    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n"," \n","    response = requests.get(URL)    \n","    html = response.text                                   \n","    soup = BeautifulSoup(html, 'html.parser')           \n","\n","    title = soup.find('h3', class_='petitionsView_title')\n","    count = soup.find('span', class_='counter')           \n","\n","    for content in soup.select('div.petitionsView_write \u003e div.View_write'):\n","        content                                         \n","\n","    a=[]\n","    for tag in soup.select('ul.petitionsView_info_list \u003e li'): \n","        a.append(tag.contents[1])\n","\n","    if len(a) != 0:\n","        df1=pd.DataFrame({ 'start' : [a[1]],                \n","                           'end' : [a[2]],                     \n","                           'category' :  [a[0]],               \n","                           'count' : [count.text],             \n","                           'title': [title.text],              \n","                           'content': [content.text.strip()[0:13000]]                              \n","                         })\n","\n","        result=pd.concat([result, df1])                        \n","        result.index = np.arange(len(result))             \n","\n","    if i % 60 == 0:                                        \n","        print(\"Sleep 90seconds. Count:\" + str(i)           \n","              +\",  Local Time:\"+ time.strftime('%Y-%m-%d', time.localtime(time.time()))\n","              +\" \"+ time.strftime('%X', time.localtime(time.time()))\n","              +\",  Data Length:\"+ str(len(result)))        \n","        time.sleep(90) "]},{"cell_type":"markdown","metadata":{"id":"0aXKK0J99cX7"},"source":["[크롤링 데이터 확인]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2knq7omi9cX8"},"outputs":[],"source":["print(result.shape)\n","\n","df = result\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"OF3lBMYo9cX8"},"source":["[데이터 엑셀로 저장]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"0pMfoTcG9cX9"},"outputs":[],"source":["df.to_csv('data/crawling.csv', index = False, encoding = 'utf-8-sig')"]},{"cell_type":"markdown","metadata":{"id":"MV9EdWgN9cX_"},"source":["# 2.2 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Jgod1rQa9cX_"},"outputs":[],"source":["df.loc[1]['content']  # 전처리 전"]},{"cell_type":"markdown","metadata":{"id":"ElgU-7_k9cYB"},"source":["[전처리]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"lrV1uG1p9cYC"},"outputs":[],"source":["import re\n","\n","def remove_white_space(text):\n","    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n","    return text\n","\n","def remove_special_char(text):\n","    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n","    return text\n","\n","df.title = df.title.apply(remove_white_space)\n","df.title = df.title.apply(remove_special_char)\n","\n","df.content = df.content.apply(remove_white_space)\n","df.content = df.content.apply(remove_special_char)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8n1VWVLh9cYC"},"outputs":[],"source":["df.loc[1]['content']  # 전처리 후"]},{"cell_type":"markdown","metadata":{"id":"9XEMywpt9cYD"},"source":["# 2.3 토크나이징 및 변수 생성"]},{"cell_type":"markdown","metadata":{"id":"UnYWQtJI9cYD"},"source":["[토크나이징]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"WSer2oOW9cYI"},"outputs":[],"source":["from konlpy.tag import Okt\n","\n","okt = Okt()\n","\n","df['title_token'] = df.title.apply(okt.morphs)\n","df['content_token'] = df.content.apply(okt.nouns)"]},{"cell_type":"markdown","metadata":{"id":"mRe2-NXA9cYI"},"source":["[파생변수 생성]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2_pd_gc-9cYI"},"outputs":[],"source":["df['token_final'] = df.title_token + df.content_token\n","\n","df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n","\n","print(df.dtypes)\n","\n","df['label'] = df['count'].apply(lambda x: 'Yes' if x\u003e=1000 else 'No')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"JSFr64PE9cYJ"},"outputs":[],"source":["df_drop = df[['token_final', 'label']]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"3ojWfhTX9cYJ"},"outputs":[],"source":["df_drop.head()"]},{"cell_type":"markdown","metadata":{"id":"fAlW2KQx9cYJ"},"source":["[데이터 엑셀로 저장]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"nqWOYVdq9cYJ"},"outputs":[],"source":["df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9804,"status":"ok","timestamp":1653981578134,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"},"user_tz":-540},"id":"1RmVuHJh-33B","outputId":"f9370a08-d09b-4cb8-815e-6bb81a8b9260"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 14.42 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"]}],"source":["#!git clone https://github.com/e9t/nsmc.git"]},{"cell_type":"markdown","metadata":{"id":"HMbQBQMa9cYK"},"source":["# 2.4 단어 임베딩"]},{"cell_type":"markdown","metadata":{"id":"0KT-zmCi9cYK"},"source":["[단어 임베딩]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"gvKKl2wa9cYK"},"outputs":[],"source":["from gensim.models import Word2Vec\n","\n","embedding_model = Word2Vec(df_drop['token_final'], \n","                           sg = 1, # skip-gram\n","                           size = 100, \n","                           window = 2, \n","                           min_count = 1, \n","                           workers = 4\n","                           )\n","\n","print(embedding_model)\n","\n","model_result = embedding_model.wv.most_similar(\"음주운전\")\n","print(model_result)"]},{"cell_type":"markdown","metadata":{"id":"nG0Raqf_9cYK"},"source":["[임베딩 모델 저장 및 로드]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"60TVglyj9cYK"},"outputs":[],"source":["from gensim.models import KeyedVectors\n","\n","embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') # 모델 저장\n","loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v') # 모델 로드\n","\n","model_result = loaded_model.most_similar(\"음주운전\")\n","print(model_result)"]},{"cell_type":"markdown","metadata":{"id":"XzCM23G19cYL"},"source":["# 2.5 실험 설계"]},{"cell_type":"markdown","metadata":{"id":"eGd7ke_99cYL"},"source":["[데이터셋 분할 및 저장]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"oH2Y3yuc9cYL"},"outputs":[],"source":["from numpy.random import RandomState\n","\n","rng = RandomState()\n","\n","tr = df_drop.sample(frac=0.8, random_state=rng)\n","val = df_drop.loc[~df_drop.index.isin(tr.index)]\n","\n","tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n","val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"markdown","metadata":{"id":"NzyVyxKX9cYL"},"source":["[Field클래스 정의]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"cVrkXxP-9cYM"},"outputs":[],"source":["import torchtext\n","from torchtext.data import Field\n","\n","def tokenizer(text):\n","    text = re.sub('[\\[\\]\\']', '', str(text))\n","    text = text.split(', ')\n","    return text\n","\n","TEXT = Field(tokenize=tokenizer)\n","LABEL = Field(sequential = False)"]},{"cell_type":"markdown","metadata":{"id":"A87i9wOt9cYM"},"source":["[데이터 불러오기]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GZGu3h9o9cYM"},"outputs":[],"source":["from torchtext.data import TabularDataset\n","\n","train, validation = TabularDataset.splits(\n","    path = 'data/',\n","    train = 'train.csv',\n","    validation = 'validation.csv',\n","    format = 'csv',\n","    fields = [('text', TEXT), ('label', LABEL)],\n","    skip_header = True\n",")\n","\n","print(\"Train:\", train[0].text,  train[0].label)\n","print(\"Validation:\", validation[0].text, validation[0].label)"]},{"cell_type":"markdown","metadata":{"id":"wvE-ZCsA9cYN"},"source":["[단어장 및 DataLoader 정의]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"4Kx8vxnB9cYN"},"outputs":[],"source":["import torch\n","from torchtext.vocab import Vectors\n","from torchtext.data import BucketIterator\n","\n","vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n","\n","TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n","LABEL.build_vocab(train)\n","\n","vocab = TEXT.vocab\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","train_iter, validation_iter = BucketIterator.splits(\n","    datasets = (train, validation),\n","    batch_size = 8,\n","    device = device,\n","    sort = False\n",")\n","\n","print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"]},{"cell_type":"markdown","metadata":{"id":"ApL-Jkyd9cYN"},"source":["# 2.6 TextCNN"]},{"cell_type":"markdown","metadata":{"id":"4w--UOtl9cYN"},"source":["[TextCNN 모델링]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"f1-CfeZj9cYN"},"outputs":[],"source":["import torch.nn as nn   \n","import torch.optim as optim \n","import torch.nn.functional as F \n","\n","class TextCNN(nn.Module): \n","    \n","    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n","        \n","        super(TextCNN, self).__init__()\n","        \n","        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n","        self.embed.weight.data.copy_(vocab_built.vectors)      \n","    \n","        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n","        self.relu = nn.ReLU()                \n","        self.dropout = nn.Dropout(0.4)         \n","        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n","        \n","    def forward(self, x):  \n","      \n","        emb_x = self.embed(x)           \n","        emb_x = emb_x.unsqueeze(1)  \n","\n","        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n","\n","        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n","        \n","        fc_x = torch.cat(pool_x, dim=1) \n","        fc_x = fc_x.squeeze(-1)       \n","        fc_x = self.dropout(fc_x)         \n","\n","        logit = self.fc(fc_x)     \n","        \n","        return logit"]},{"cell_type":"markdown","metadata":{"id":"rGsmtMqe9cYO"},"source":["[모델 학습 함수 정의]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"5VBuu0d79cYO"},"outputs":[],"source":["def train(model, device, train_itr, optimizer):\n","    \n","    model.train()                               \n","    corrects, train_loss = 0.0,0        \n","    \n","    for batch in train_itr:\n","        \n","        text, target = batch.text, batch.label      \n","        text = torch.transpose(text, 0, 1)          \n","        target.data.sub_(1)                                 \n","        text, target = text.to(device), target.to(device)  \n","\n","        optimizer.zero_grad()                           \n","        logit = model(text)                         \n","    \n","        loss = F.cross_entropy(logit, target)   \n","        loss.backward()  \n","        optimizer.step()  \n","        \n","        train_loss += loss.item()    \n","        result = torch.max(logit,1)[1] \n","        corrects += (result.view(target.size()).data == target.data).sum()\n","        \n","    train_loss /= len(train_itr.dataset)\n","    accuracy = 100.0 * corrects / len(train_itr.dataset)\n","\n","    return train_loss, accuracy"]},{"cell_type":"markdown","metadata":{"id":"UAGXk-1f9cYO"},"source":["[모델 평가 함수 정의]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Ifp4Agja9cYO"},"outputs":[],"source":["def evaluate(model, device, itr):\n","    \n","    model.eval()\n","    corrects, test_loss = 0.0, 0\n","\n","    for batch in itr:\n","        \n","        text = batch.text\n","        target = batch.label\n","        text = torch.transpose(text, 0, 1)\n","        target.data.sub_(1)\n","        text, target = text.to(device), target.to(device)\n","        \n","        logit = model(text)\n","        loss = F.cross_entropy(logit, target)\n","\n","        test_loss += loss.item()\n","        result = torch.max(logit,1)[1]\n","        corrects += (result.view(target.size()).data == target.data).sum()\n","\n","    test_loss /= len(itr.dataset) \n","    accuracy = 100.0 * corrects / len(itr.dataset)\n","    \n","    return test_loss, accuracy"]},{"cell_type":"markdown","metadata":{"id":"QgYqR7q29cYO"},"source":["[모델 학습 및 성능 확인]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"NnhwqYFi9cYO"},"outputs":[],"source":["model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n","print(model)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","best_test_acc = -1\n","\n","for epoch in range(1, 3+1):\n"," \n","    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n","    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n","    \n","    val_loss, val_acc = evaluate(model, device, validation_iter)\n","    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n","        \n","    if val_acc \u003e best_test_acc:\n","        best_test_acc = val_acc\n","        \n","        print(\"model saves at {} accuracy\".format(best_test_acc))\n","        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n","    \n","    print('-----------------------------------------------------------------------------')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"11-1. gensim word representation.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}