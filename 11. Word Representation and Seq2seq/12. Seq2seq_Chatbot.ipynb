{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12. Seq2seq_Chatbot.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 주식가격 하락으로 마음아픈 나를 위로해주는 챗봇 구현하기\n"," - 참조: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"],"metadata":{"id":"D6XOiT-H-Oeo"}},{"cell_type":"markdown","source":["## 1. import pacakages"],"metadata":{"id":"XPey-FFC-oh7"}},{"cell_type":"code","source":["import random\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","torch.manual_seed(0) #to make the initial seeds\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #check whether GPU is available"],"metadata":{"id":"chIOszi8-oFe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Preparation of Datasets\n"," - 단어 표현을 위해 단어사전 만들기 단어 --> index, index --> 단어\n"],"metadata":{"id":"PMVy-aLR_bew"}},{"cell_type":"code","source":["#!pip install Korpora\n","#from Korpora import Korpora\n","#Korpora.corpus_list()"],"metadata":{"id":"UuomjmLQd6Rh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/songys/Chatbot_data.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5FZpXJReM1e","executionInfo":{"status":"ok","timestamp":1654136154986,"user_tz":-540,"elapsed":1027,"user":{"displayName":"김민지컴퓨터공학과","userId":"13647181858739443443"}},"outputId":"2afb19db-022e-42f9-89fc-60a492669dbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Chatbot_data'...\n","remote: Enumerating objects: 57, done.\u001b[K\n","remote: Counting objects: 100% (39/39), done.\u001b[K\n","remote: Compressing objects: 100% (36/36), done.\u001b[K\n","remote: Total 57 (delta 21), reused 6 (delta 3), pack-reused 18\u001b[K\n","Unpacking objects: 100% (57/57), done.\n"]}]},{"cell_type":"code","source":["raw = pd.read_csv(\"./Chatbot_data/ChatbotData.csv\")"],"metadata":{"id":"lCfZySDykMV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qa_list = raw[[\"Q\",\"A\"]]\n","qa_list = qa_list.values.tolist()"],"metadata":{"id":"nRX4d0gFkd2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#참조 모두의 딥러닝 시즌2\n","SOS_token = 0\n","EOS_token = 1\n","UNK_token = 2\n","\n","# class for vocabulary related information of data\n","class Vocab:\n","    def __init__(self):\n","        self.vocab2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token, \"<UNK>\": UNK_token}\n","        self.index2vocab = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\", UNK_token: \"<UNK>\"}\n","        self.vocab_count = {}\n","        self.n_vocab = len(self.vocab2index)\n","\n","    def add_vocab(self, sentence):\n","        for word in sentence.split(\" \"):\n","            if word not in self.vocab2index:\n","                self.vocab2index[word] = self.n_vocab\n","                self.vocab_count[word] = 1\n","                self.index2vocab[self.n_vocab] = word\n","                self.n_vocab += 1\n","            else:\n","                self.vocab_count[word] += 1\n"],"metadata":{"id":"NSs30GIJ_mxv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["  - 데이터 전처리: 학습데이터로 만들기"],"metadata":{"id":"iuVLZWmqYa7o"}},{"cell_type":"code","source":["# read and preprocess the corpus data\n","def preprocess_df(corpus, source_max_length, target_max_length):\n","    print(\"reading corpus...\")\n","    pairs = corpus\n","\n","    source_vocab = Vocab()\n","    target_vocab = Vocab()\n","\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        source_vocab.add_vocab(pair[0])\n","        target_vocab.add_vocab(pair[1])\n","    print(\"source vocab size =\", source_vocab.n_vocab)\n","    print(\"target vocab size =\", target_vocab.n_vocab)\n","\n","    return pairs, source_vocab, target_vocab"],"metadata":{"id":"adZI8k1JleV2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Model Classes"],"metadata":{"id":"rSR6LSMTYn2e"}},{"cell_type":"markdown","source":["### 3-1. Encoder"],"metadata":{"id":"0OoBv_YyYsSY"}},{"cell_type":"code","source":["# declare simple encoder\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        return x, hidden"],"metadata":{"id":"cDeA7v8pYnP0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3-2. Decoder"],"metadata":{"id":"K3feRbYpYu2j"}},{"cell_type":"code","source":["# declare simple decoder\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x).view(1, 1, -1)\n","        x, hidden = self.gru(x, hidden)\n","        x = self.softmax(self.out(x[0]))\n","        return x, hidden"],"metadata":{"id":"mg_glwuBYwHR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Train function"],"metadata":{"id":"Iea4Z5BdY4XQ"}},{"cell_type":"code","source":["# convert sentence to the index tensor\n","def tensorize(vocab, sentence):\n","    #indexes = [vocab.vocab2index[word] for word in sentence.split(\" \")]\n","    indexes = [vocab.vocab2index[word] if word in vocab.vocab2index else UNK_token for word in sentence.split(\" \")]\n","    indexes.append(vocab.vocab2index[\"<EOS>\"])\n","    return torch.Tensor(indexes).long().to(device).view(-1, 1)"],"metadata":{"id":"R04_hWwbY3R7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training seq2seq\n","def train(pairs, source_vocab, target_vocab, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iter, print_every=1000, learning_rate=0.01):\n","    encoder.train()\n","    decoder.train()\n","    loss_total = 0\n","\n","    training_batch = [random.choice(pairs) for _ in range(n_iter)]\n","    training_source = [tensorize(source_vocab, pair[0]) for pair in training_batch]\n","    training_target = [tensorize(target_vocab, pair[1]) for pair in training_batch]\n","\n","    criterion = nn.NLLLoss()\n","\n","    for i in range(1, n_iter + 1):\n","        source_tensor = training_source[i - 1]\n","        target_tensor = training_target[i - 1]\n","\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","\n","        source_length = source_tensor.size(0)\n","        target_length = target_tensor.size(0)\n","\n","        loss = 0\n","\n","        for enc_input in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[enc_input], encoder_hidden)\n","\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden # connect encoder output to decoder input\n","\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # teacher forcing\n","\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","        loss_iter = loss.item() / target_length\n","        loss_total += loss_iter\n","\n","        if i % print_every == 0:\n","            loss_avg = loss_total / print_every\n","            loss_total = 0\n","            print(\"[{} - {}%] loss = {:05.4f}\".format(i, i / n_iter * 100, loss_avg))"],"metadata":{"id":"UMNsfdj-Y-1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# insert given sentence to check the training\n","def evaluate(pairs, source_vocab, target_vocab, encoder, decoder, target_max_length, print_every=5):\n","    encoder.eval()\n","    decoder.eval()\n","    for idx, pair in enumerate(pairs):\n","\n","        source_tensor = tensorize(source_vocab, pair[0])\n","        source_length = source_tensor.size()[0]\n","        encoder_hidden = torch.zeros([1, 1, encoder.hidden_size]).to(device)\n","\n","        for ei in range(source_length):\n","            _, encoder_hidden = encoder(source_tensor[ei], encoder_hidden)\n","\n","        #decoder_input = torch.Tensor([[SOS_token]], device=device).long()\n","        decoder_input = torch.Tensor([[SOS_token]]).long().to(device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","\n","        for di in range(target_max_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            _, top_index = decoder_output.data.topk(1)\n","            if top_index.item() == EOS_token:\n","                decoded_words.append(\"<EOS>\")\n","                break\n","            else:\n","                decoded_words.append(target_vocab.index2vocab[top_index.item()])\n","\n","            decoder_input = top_index.squeeze().detach()\n","\n","        predict_words = decoded_words\n","        predict_sentence = \" \".join(predict_words)\n","        if idx%print_every==0:\n","          print(\">\", pair[0]) \n","          print(\"=\", pair[1])\n","          print(\"<\", predict_sentence)\n","          print(\"\")"],"metadata":{"id":"TRBFHr8jiMoy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Main function"],"metadata":{"id":"JJWQ7Q3JfiQT"}},{"cell_type":"code","source":["SOURCE_MAX_LENGTH = 50\n","TARGET_MAX_LENGTH = 50"],"metadata":{"id":"tbtLVjnnhG2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_pairs, load_source_vocab, load_target_vocab = preprocess_df(qa_list, source_max_length=SOURCE_MAX_LENGTH, target_max_length=TARGET_MAX_LENGTH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXfZzkijffo0","executionInfo":{"status":"ok","timestamp":1653977064211,"user_tz":-540,"elapsed":3,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"5e0794c9-093a-4dca-d34e-47719281acc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["reading corpus...\n","Counting words...\n","source vocab size = 14287\n","target vocab size = 10008\n"]}]},{"cell_type":"code","source":["qa_list[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e42RgV0-otst","executionInfo":{"status":"ok","timestamp":1653977065594,"user_tz":-540,"elapsed":3,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"9cf12ac1-9369-481c-96d1-84c957f90296"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['12시 땡!', '하루가 또 가네요.'],\n"," ['1지망 학교 떨어졌어', '위로해 드립니다.'],\n"," ['3박4일 놀러가고 싶다', '여행은 언제나 좋죠.']]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["load_source_vocab.vocab2index[\"안녕\"], load_source_vocab.index2vocab[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q90DLpREgD0m","executionInfo":{"status":"ok","timestamp":1653977066627,"user_tz":-540,"elapsed":4,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"a1549a4d-a453-4ae7-f5b9-b146a99beb93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4006, '<UNK>')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["load_source_vocab.n_vocab, load_target_vocab.n_vocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0jo1GebhRv_","executionInfo":{"status":"ok","timestamp":1653977068048,"user_tz":-540,"elapsed":3,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"ce6ca74e-d47f-4208-d25d-b4e72a1ca941"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14287, 10008)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["enc_hidden_size = 100\n","dec_hidden_size = enc_hidden_size\n","encoder = Encoder(input_size=load_source_vocab.n_vocab, hidden_size=enc_hidden_size).to(device)\n","decoder = Decoder(hidden_size=dec_hidden_size, output_size=load_target_vocab.n_vocab).to(device)\n","\n","learning_rate = 0.01\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)"],"metadata":{"id":"nB1HN0r0g5Nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(load_pairs, load_source_vocab, load_target_vocab, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iter=len(load_pairs)*5, print_every=500)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0riGMqBagF-B","executionInfo":{"status":"ok","timestamp":1653979360759,"user_tz":-540,"elapsed":358041,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"4e8aa25f-dc6a-48f7-f411-ff7ec1a23358"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[500 - 0.8458090163241141%] loss = 4.3966\n","[1000 - 1.6916180326482282%] loss = 4.3783\n","[1500 - 2.537427048972342%] loss = 4.4091\n","[2000 - 3.3832360652964564%] loss = 4.2440\n","[2500 - 4.22904508162057%] loss = 4.3350\n","[3000 - 5.074854097944684%] loss = 4.4052\n","[3500 - 5.920663114268798%] loss = 4.3977\n","[4000 - 6.766472130592913%] loss = 4.4182\n","[4500 - 7.6122811469170255%] loss = 4.2964\n","[5000 - 8.45809016324114%] loss = 4.2817\n","[5500 - 9.303899179565255%] loss = 4.3114\n","[6000 - 10.149708195889367%] loss = 4.3040\n","[6500 - 10.995517212213482%] loss = 4.2924\n","[7000 - 11.841326228537596%] loss = 4.3173\n","[7500 - 12.687135244861711%] loss = 4.1709\n","[8000 - 13.532944261185825%] loss = 4.1732\n","[8500 - 14.378753277509936%] loss = 4.2448\n","[9000 - 15.224562293834051%] loss = 4.1931\n","[9500 - 16.070371310158166%] loss = 4.1457\n","[10000 - 16.91618032648228%] loss = 4.1534\n","[10500 - 17.761989342806395%] loss = 4.1864\n","[11000 - 18.60779835913051%] loss = 4.1653\n","[11500 - 19.453607375454624%] loss = 4.0724\n","[12000 - 20.299416391778735%] loss = 4.0225\n","[12500 - 21.14522540810285%] loss = 4.0361\n","[13000 - 21.991034424426964%] loss = 4.1564\n","[13500 - 22.83684344075108%] loss = 3.9771\n","[14000 - 23.682652457075193%] loss = 3.9529\n","[14500 - 24.528461473399307%] loss = 4.1313\n","[15000 - 25.374270489723422%] loss = 3.9299\n","[15500 - 26.220079506047533%] loss = 3.9999\n","[16000 - 27.06588852237165%] loss = 3.8541\n","[16500 - 27.911697538695762%] loss = 4.0352\n","[17000 - 28.757506555019873%] loss = 3.9471\n","[17500 - 29.60331557134399%] loss = 3.8799\n","[18000 - 30.449124587668102%] loss = 3.8606\n","[18500 - 31.29493360399222%] loss = 3.7705\n","[19000 - 32.14074262031633%] loss = 3.7625\n","[19500 - 32.98655163664045%] loss = 3.9676\n","[20000 - 33.83236065296456%] loss = 3.8000\n","[20500 - 34.67816966928867%] loss = 3.8247\n","[21000 - 35.52397868561279%] loss = 3.9048\n","[21500 - 36.3697877019369%] loss = 3.8576\n","[22000 - 37.21559671826102%] loss = 3.8474\n","[22500 - 38.06140573458513%] loss = 3.7476\n","[23000 - 38.90721475090925%] loss = 3.7560\n","[23500 - 39.75302376723336%] loss = 3.7897\n","[24000 - 40.59883278355747%] loss = 3.8318\n","[24500 - 41.44464179988159%] loss = 3.7741\n","[25000 - 42.2904508162057%] loss = 3.7074\n","[25500 - 43.13625983252982%] loss = 3.7383\n","[26000 - 43.98206884885393%] loss = 3.6627\n","[26500 - 44.827877865178046%] loss = 3.5575\n","[27000 - 45.67368688150216%] loss = 3.6661\n","[27500 - 46.51949589782627%] loss = 3.7512\n","[28000 - 47.365304914150386%] loss = 3.6698\n","[28500 - 48.2111139304745%] loss = 3.6387\n","[29000 - 49.056922946798615%] loss = 3.5844\n","[29500 - 49.902731963122726%] loss = 3.5854\n","[30000 - 50.748540979446844%] loss = 3.6383\n","[30500 - 51.59434999577095%] loss = 3.5383\n","[31000 - 52.440159012095066%] loss = 3.5530\n","[31500 - 53.285968028419184%] loss = 3.5447\n","[32000 - 54.1317770447433%] loss = 3.5017\n","[32500 - 54.977586061067406%] loss = 3.4860\n","[33000 - 55.823395077391524%] loss = 3.5748\n","[33500 - 56.66920409371564%] loss = 3.4421\n","[34000 - 57.515013110039746%] loss = 3.5006\n","[34500 - 58.360822126363864%] loss = 3.4177\n","[35000 - 59.20663114268798%] loss = 3.4794\n","[35500 - 60.0524401590121%] loss = 3.4009\n","[36000 - 60.898249175336204%] loss = 3.3351\n","[36500 - 61.74405819166032%] loss = 3.4594\n","[37000 - 62.58986720798444%] loss = 3.4021\n","[37500 - 63.435676224308544%] loss = 3.4331\n","[38000 - 64.28148524063266%] loss = 3.3985\n","[38500 - 65.12729425695679%] loss = 3.3570\n","[39000 - 65.9731032732809%] loss = 3.4004\n","[39500 - 66.81891228960501%] loss = 3.3709\n","[40000 - 67.66472130592912%] loss = 3.4009\n","[40500 - 68.51053032225323%] loss = 3.3065\n","[41000 - 69.35633933857734%] loss = 3.2418\n","[41500 - 70.20214835490147%] loss = 3.3295\n","[42000 - 71.04795737122558%] loss = 3.2831\n","[42500 - 71.89376638754969%] loss = 3.3622\n","[43000 - 72.7395754038738%] loss = 3.2522\n","[43500 - 73.58538442019793%] loss = 3.2861\n","[44000 - 74.43119343652204%] loss = 3.2493\n","[44500 - 75.27700245284615%] loss = 3.2265\n","[45000 - 76.12281146917026%] loss = 3.2868\n","[45500 - 76.96862048549437%] loss = 3.1702\n","[46000 - 77.8144295018185%] loss = 3.2817\n","[46500 - 78.6602385181426%] loss = 3.2370\n","[47000 - 79.50604753446672%] loss = 3.1517\n","[47500 - 80.35185655079083%] loss = 3.1379\n","[48000 - 81.19766556711494%] loss = 3.1639\n","[48500 - 82.04347458343906%] loss = 3.2505\n","[49000 - 82.88928359976317%] loss = 3.0151\n","[49500 - 83.73509261608729%] loss = 3.2434\n","[50000 - 84.5809016324114%] loss = 3.0602\n","[50500 - 85.42671064873552%] loss = 3.0428\n","[51000 - 86.27251966505963%] loss = 3.0896\n","[51500 - 87.11832868138374%] loss = 3.0541\n","[52000 - 87.96413769770786%] loss = 3.0769\n","[52500 - 88.80994671403198%] loss = 3.0088\n","[53000 - 89.65575573035609%] loss = 3.0906\n","[53500 - 90.5015647466802%] loss = 3.0854\n","[54000 - 91.34737376300431%] loss = 3.0519\n","[54500 - 92.19318277932842%] loss = 2.9738\n","[55000 - 93.03899179565254%] loss = 3.1603\n","[55500 - 93.88480081197666%] loss = 2.8843\n","[56000 - 94.73060982830077%] loss = 3.0641\n","[56500 - 95.57641884462488%] loss = 2.9776\n","[57000 - 96.422227860949%] loss = 2.9785\n","[57500 - 97.26803687727312%] loss = 2.9095\n","[58000 - 98.11384589359723%] loss = 3.0012\n","[58500 - 98.95965490992134%] loss = 2.9703\n","[59000 - 99.80546392624545%] loss = 2.9540\n"]}]},{"cell_type":"code","source":["# check the model with given data\n","evaluate(load_pairs, load_source_vocab, load_target_vocab, encoder, decoder, TARGET_MAX_LENGTH, print_every=5000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__kQ_2nShqsn","executionInfo":{"status":"ok","timestamp":1653979663437,"user_tz":-540,"elapsed":31632,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"ee1cd651-2fe1-43b9-9eab-fb7d49b5d73f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["> 12시 땡!\n","= 하루가 또 가네요.\n","< 저는 위기 조차 없네요. <EOS>\n","\n","> 학원폭력 짜증나\n","= 학교 폭력은 범죄에요.\n","< 좋은 사람이라면 고마워할 거예요. <EOS>\n","\n","> 사랑한다고 말해주면 뭐가 덧나나\n","= 사랑한다고 표현해달라고 말해보세요.\n","< 사랑은 유지하는 게 중요한데 대단하네요. <EOS>\n","\n"]}]},{"cell_type":"code","source":["a_test_sample = [['무슨 개소리를 이렇게 장황하게해', '?']]"],"metadata":{"id":"bAasU1NUjkrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(a_test_sample, load_source_vocab, load_target_vocab, encoder, decoder, TARGET_MAX_LENGTH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2GEMa8ajvWW","executionInfo":{"status":"ok","timestamp":1653980170910,"user_tz":-540,"elapsed":303,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"6e15f7c7-3417-4cdf-8625-2a91d8d4b47b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["> 무슨 개소리를 이렇게 장황하게해\n","= ?\n","< 잘 견뎌내고 있네요. <EOS>\n","\n"]}]},{"cell_type":"markdown","source":["## 실습0: seq2seq 모델의 모델 부분을 구현해 보세요!"],"metadata":{"id":"lmr_1htl2Vyw"}},{"cell_type":"markdown","source":["## 실습1: Unknown Token을 처리하시오!!\n","  - 한번도 나온적 없는 데이터를 입력으로 받을 경우 챗봇이 오류를 내고 있습니다. 해당 문제는 한번도 못본 단어를 \"\\<UNK\\>\" 라는 단어로 치환하는 방법인데요. 어떻게 구현할 수 있을까요?"],"metadata":{"id":"B4y7G5vRrPMj"}},{"cell_type":"markdown","source":["## 실습2: 해당 코드의 데이터를 변경해서 기계번역기, 남자/여자 언어 번역기를 개발해보세요!"],"metadata":{"id":"DlUMSyqA5x_x"}},{"cell_type":"code","source":[""],"metadata":{"id":"hFZVAIF-55wi"},"execution_count":null,"outputs":[]}]}