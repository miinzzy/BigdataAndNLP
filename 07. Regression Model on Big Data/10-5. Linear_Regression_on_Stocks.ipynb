{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10-5. Linear_Regression_on_Stocks.ipynb","provenance":[],"collapsed_sections":["_AIyyBNuv-9Z","ruoJovvcwD32","TNMOttK54rBV","oixYOm_SJR0A"],"authorship_tag":"ABX9TyPMW5yFW9MVOEju91Q/zCct"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Linear Regression 기반의 검색 빈도수를 이용한 주가예측"],"metadata":{"id":"iH_xs7RAv4n2"}},{"cell_type":"markdown","source":["# 0. Install packages"],"metadata":{"id":"_AIyyBNuv-9Z"}},{"cell_type":"code","source":["!pip install finance-datareader\n","!pip install -U finance-datareader # 업데이트"],"metadata":{"id":"b5OtrBfkv3VS","executionInfo":{"status":"ok","timestamp":1649892800783,"user_tz":-540,"elapsed":13908,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a0f32ea-a3af-46d5-c8f1-2631030e95bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting finance-datareader\n","  Downloading finance_datareader-0.9.33-py3-none-any.whl (48 kB)\n","\u001b[?25l\r\u001b[K     |██████▊                         | 10 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 20 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 40 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 48 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.2.6)\n","Collecting requests-file\n","  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n","Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (2.23.0)\n","Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.64.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.2->finance-datareader) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n","Installing collected packages: requests-file, finance-datareader\n","Successfully installed finance-datareader-0.9.33 requests-file-1.5.1\n","Requirement already satisfied: finance-datareader in /usr/local/lib/python3.7/dist-packages (0.9.33)\n","Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.64.0)\n","Requirement already satisfied: requests-file in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (1.5.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.2.6)\n","Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (2.23.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (1.21.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.2->finance-datareader) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import urllib.request\n","import json\n","import re"],"metadata":{"id":"CmhLKqq13fUE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Prepare datasests"],"metadata":{"id":"ruoJovvcwD32"}},{"cell_type":"markdown","source":["## 1-1. 주가 데이터 불러오기"],"metadata":{"id":"YumVDrMY6eCu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJa9ai4wv2pD","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1649892815470,"user_tz":-540,"elapsed":7524,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"3dfe45b3-91f1-4a97-b2fd-c5aa26132fdf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Symbol  Market    Name           Sector             Industry ListingDate  \\\n","0  060310  KOSDAQ      3S         전자부품 제조업          반도체 웨이퍼 캐리어  2002-04-23   \n","1  095570   KOSPI  AJ네트웍스  산업용 기계 및 장비 임대업  렌탈(파렛트, OA장비, 건설장비)  2015-08-21   \n","2  006840   KOSPI   AK홀딩스           기타 금융업                 지주사업  1999-08-11   \n","3  054620  KOSDAQ  APS홀딩스           기타 금융업          인터넷 트래픽 솔루션  2001-12-04   \n","4  265520  KOSDAQ   AP시스템    특수 목적용 기계 제조업          디스플레이 제조 장비  2017-04-07   \n","\n","  SettleMonth     Representative                       HomePage Region  \n","0         03월                김세완           http://www.3sref.com  서울특별시  \n","1         12월           박대현, 손삼달         http://www.ajnet.co.kr  서울특별시  \n","2         12월  채형석, 이석주(각자 대표이사)  http://www.aekyunggroup.co.kr  서울특별시  \n","3         12월                정기로   http://www.apsholdings.co.kr    경기도  \n","4         12월                김영주     http://www.apsystems.co.kr    경기도  "],"text/html":["\n","  <div id=\"df-c5799199-ad4b-44cb-b3d0-cb8476f19057\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Symbol</th>\n","      <th>Market</th>\n","      <th>Name</th>\n","      <th>Sector</th>\n","      <th>Industry</th>\n","      <th>ListingDate</th>\n","      <th>SettleMonth</th>\n","      <th>Representative</th>\n","      <th>HomePage</th>\n","      <th>Region</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>060310</td>\n","      <td>KOSDAQ</td>\n","      <td>3S</td>\n","      <td>전자부품 제조업</td>\n","      <td>반도체 웨이퍼 캐리어</td>\n","      <td>2002-04-23</td>\n","      <td>03월</td>\n","      <td>김세완</td>\n","      <td>http://www.3sref.com</td>\n","      <td>서울특별시</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>095570</td>\n","      <td>KOSPI</td>\n","      <td>AJ네트웍스</td>\n","      <td>산업용 기계 및 장비 임대업</td>\n","      <td>렌탈(파렛트, OA장비, 건설장비)</td>\n","      <td>2015-08-21</td>\n","      <td>12월</td>\n","      <td>박대현, 손삼달</td>\n","      <td>http://www.ajnet.co.kr</td>\n","      <td>서울특별시</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>006840</td>\n","      <td>KOSPI</td>\n","      <td>AK홀딩스</td>\n","      <td>기타 금융업</td>\n","      <td>지주사업</td>\n","      <td>1999-08-11</td>\n","      <td>12월</td>\n","      <td>채형석, 이석주(각자 대표이사)</td>\n","      <td>http://www.aekyunggroup.co.kr</td>\n","      <td>서울특별시</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>054620</td>\n","      <td>KOSDAQ</td>\n","      <td>APS홀딩스</td>\n","      <td>기타 금융업</td>\n","      <td>인터넷 트래픽 솔루션</td>\n","      <td>2001-12-04</td>\n","      <td>12월</td>\n","      <td>정기로</td>\n","      <td>http://www.apsholdings.co.kr</td>\n","      <td>경기도</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>265520</td>\n","      <td>KOSDAQ</td>\n","      <td>AP시스템</td>\n","      <td>특수 목적용 기계 제조업</td>\n","      <td>디스플레이 제조 장비</td>\n","      <td>2017-04-07</td>\n","      <td>12월</td>\n","      <td>김영주</td>\n","      <td>http://www.apsystems.co.kr</td>\n","      <td>경기도</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5799199-ad4b-44cb-b3d0-cb8476f19057')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c5799199-ad4b-44cb-b3d0-cb8476f19057 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c5799199-ad4b-44cb-b3d0-cb8476f19057');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["# Random seed to make results deterministic and reproducible\n","torch.manual_seed(0)\n","\n","# 한국거래소에 상장된 모든 종목 리스트 가져오기\n","import FinanceDataReader as fdr\n","df_krx = fdr.StockListing('KRX')\n","df_krx.head()"]},{"cell_type":"code","source":["df = fdr.DataReader('036570','2020-01-01', '2022-04-12') # NCsoft 주가를 2020년부터 현시점까지 가져온다"],"metadata":{"id":"hRD8JZyy1kSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"9yar11nd3Qy0","executionInfo":{"status":"ok","timestamp":1649892816033,"user_tz":-540,"elapsed":7,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"1a9b3145-5480-4c12-82c4-abb73b1a5fcb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Open    High     Low   Close  Volume    Change\n","Date                                                        \n","2020-01-02  542000  545000  539000  541000   40246  0.000000\n","2020-01-03  547000  568000  542000  565000  112404  0.044362\n","2020-01-06  562000  587000  562000  579000  107006  0.024779\n","2020-01-07  583000  596000  574000  594000   84378  0.025907\n","2020-01-08  587000  604000  584000  604000  109267  0.016835\n","...            ...     ...     ...     ...     ...       ...\n","2022-04-06  475000  483500  469000  474000   96750 -0.012500\n","2022-04-07  469000  471500  462000  462000  103079 -0.025316\n","2022-04-08  462500  466500  453500  458000   87055 -0.008658\n","2022-04-11  450500  459000  449000  453500   59322 -0.009825\n","2022-04-12  452000  461500  446500  458000  100684  0.009923\n","\n","[563 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-190f5d98-0ba9-4a0b-8883-85c2f3fbd63b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>Change</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2020-01-02</th>\n","      <td>542000</td>\n","      <td>545000</td>\n","      <td>539000</td>\n","      <td>541000</td>\n","      <td>40246</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-03</th>\n","      <td>547000</td>\n","      <td>568000</td>\n","      <td>542000</td>\n","      <td>565000</td>\n","      <td>112404</td>\n","      <td>0.044362</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-06</th>\n","      <td>562000</td>\n","      <td>587000</td>\n","      <td>562000</td>\n","      <td>579000</td>\n","      <td>107006</td>\n","      <td>0.024779</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-07</th>\n","      <td>583000</td>\n","      <td>596000</td>\n","      <td>574000</td>\n","      <td>594000</td>\n","      <td>84378</td>\n","      <td>0.025907</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-08</th>\n","      <td>587000</td>\n","      <td>604000</td>\n","      <td>584000</td>\n","      <td>604000</td>\n","      <td>109267</td>\n","      <td>0.016835</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-06</th>\n","      <td>475000</td>\n","      <td>483500</td>\n","      <td>469000</td>\n","      <td>474000</td>\n","      <td>96750</td>\n","      <td>-0.012500</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-07</th>\n","      <td>469000</td>\n","      <td>471500</td>\n","      <td>462000</td>\n","      <td>462000</td>\n","      <td>103079</td>\n","      <td>-0.025316</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-08</th>\n","      <td>462500</td>\n","      <td>466500</td>\n","      <td>453500</td>\n","      <td>458000</td>\n","      <td>87055</td>\n","      <td>-0.008658</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-11</th>\n","      <td>450500</td>\n","      <td>459000</td>\n","      <td>449000</td>\n","      <td>453500</td>\n","      <td>59322</td>\n","      <td>-0.009825</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-12</th>\n","      <td>452000</td>\n","      <td>461500</td>\n","      <td>446500</td>\n","      <td>458000</td>\n","      <td>100684</td>\n","      <td>0.009923</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>563 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-190f5d98-0ba9-4a0b-8883-85c2f3fbd63b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-190f5d98-0ba9-4a0b-8883-85c2f3fbd63b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-190f5d98-0ba9-4a0b-8883-85c2f3fbd63b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df = df.fillna(0)"],"metadata":{"id":"4EG7lm7M3TP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(df['Close'], 'bo-')\n","plt.xticks(rotation=45)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"Cxp628qL3wVT","executionInfo":{"status":"ok","timestamp":1649892817037,"user_tz":-540,"elapsed":1010,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"6b38c190-2f53-40f4-9dfd-3cb5deffac05"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([737425., 737516., 737607., 737699., 737791., 737881., 737972.,\n","        738064., 738156., 738246.]),\n"," <a list of 10 Text major ticklabel objects>)"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## 1-2. Naver API 키워드 검색 데이터 불러오기"],"metadata":{"id":"L16p9sjj6jHB"}},{"cell_type":"code","source":["import os\n","import sys\n","import urllib.request\n","client_id = \"8sAydq_QSOxKcICuD2Og\"\n","client_secret = \"OruQjbmaXF\"\n","url = \"https://openapi.naver.com/v1/datalab/search\";\n","body = \"{\\\"startDate\\\":\\\"2020-01-01\\\",\\\"endDate\\\":\\\"2022-04-12\\\",\\\"timeUnit\\\":\\\"date\\\",\\\"keywordGroups\\\":[{\\\"groupName\\\":\\\"리니지\\\",\\\"keywords\\\":[\\\"리니지\\\",\\\"Lineage\\\"]}],\\\"device\\\":\\\"pc\\\",\\\"ages\\\":[\\\"1\\\",\\\"2\\\"],\\\"gender\\\":\\\"m\\\"}\";\n","\n","request = urllib.request.Request(url)\n","request.add_header(\"X-Naver-Client-Id\",client_id)\n","request.add_header(\"X-Naver-Client-Secret\",client_secret)\n","request.add_header(\"Content-Type\",\"application/json\")\n","response = urllib.request.urlopen(request, data=body.encode(\"utf-8\"))\n","rescode = response.getcode()\n","if(rescode==200):\n","    response_body = response.read()\n","    #print(response_body.decode('utf-8'))\n","    search_count = response_body.decode('utf-8')\n","else:\n","    print(\"Error Code:\" + rescode)"],"metadata":{"id":"sNK97GaS6okU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["search_count_json = json.loads(search_count)"],"metadata":{"id":"LtYJfefd8M1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_json = pd.DataFrame(search_count_json[\"results\"][0][\"data\"])"],"metadata":{"id":"CTbIXmZF8k7c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"nsrm8d6Y9XW0","executionInfo":{"status":"ok","timestamp":1649892817610,"user_tz":-540,"elapsed":8,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"03b9c808-4c22-4a50-dff5-9f2c7f1acdc7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         period     ratio\n","0    2020-01-01  35.08771\n","1    2020-01-02  35.08771\n","2    2020-01-03  17.54385\n","3    2020-01-04  26.31578\n","4    2020-01-05  14.03508\n","..          ...       ...\n","826  2022-04-08   7.01754\n","827  2022-04-09  14.03508\n","828  2022-04-10  10.52631\n","829  2022-04-11   8.77192\n","830  2022-04-12   8.77192\n","\n","[831 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-2d30a5c8-77cb-40a0-b91e-8bdfded25f49\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>period</th>\n","      <th>ratio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01</td>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-02</td>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-03</td>\n","      <td>17.54385</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-01-04</td>\n","      <td>26.31578</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-01-05</td>\n","      <td>14.03508</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>826</th>\n","      <td>2022-04-08</td>\n","      <td>7.01754</td>\n","    </tr>\n","    <tr>\n","      <th>827</th>\n","      <td>2022-04-09</td>\n","      <td>14.03508</td>\n","    </tr>\n","    <tr>\n","      <th>828</th>\n","      <td>2022-04-10</td>\n","      <td>10.52631</td>\n","    </tr>\n","    <tr>\n","      <th>829</th>\n","      <td>2022-04-11</td>\n","      <td>8.77192</td>\n","    </tr>\n","    <tr>\n","      <th>830</th>\n","      <td>2022-04-12</td>\n","      <td>8.77192</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>831 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d30a5c8-77cb-40a0-b91e-8bdfded25f49')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d30a5c8-77cb-40a0-b91e-8bdfded25f49 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d30a5c8-77cb-40a0-b91e-8bdfded25f49');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## 1-3. 데이터 전처리 및 Merge하기"],"metadata":{"id":"nYnUNmB-JjXP"}},{"cell_type":"code","source":["df_json.columns = ['Date', 'Count']"],"metadata":{"id":"WTSnDmBLE701"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_json['Date'] = pd.to_datetime(df_json['Date'])"],"metadata":{"id":"WBhzuj6qHFHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"lSWLXLdtHXhA","executionInfo":{"status":"ok","timestamp":1649892821993,"user_tz":-540,"elapsed":5,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"7dfa4b53-421a-4cee-a9d0-e91fe66d65ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Date     Count\n","0   2020-01-01  35.08771\n","1   2020-01-02  35.08771\n","2   2020-01-03  17.54385\n","3   2020-01-04  26.31578\n","4   2020-01-05  14.03508\n","..         ...       ...\n","826 2022-04-08   7.01754\n","827 2022-04-09  14.03508\n","828 2022-04-10  10.52631\n","829 2022-04-11   8.77192\n","830 2022-04-12   8.77192\n","\n","[831 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-a6c0eefa-b27b-49ea-ad64-00813df4b555\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01</td>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-02</td>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-03</td>\n","      <td>17.54385</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-01-04</td>\n","      <td>26.31578</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-01-05</td>\n","      <td>14.03508</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>826</th>\n","      <td>2022-04-08</td>\n","      <td>7.01754</td>\n","    </tr>\n","    <tr>\n","      <th>827</th>\n","      <td>2022-04-09</td>\n","      <td>14.03508</td>\n","    </tr>\n","    <tr>\n","      <th>828</th>\n","      <td>2022-04-10</td>\n","      <td>10.52631</td>\n","    </tr>\n","    <tr>\n","      <th>829</th>\n","      <td>2022-04-11</td>\n","      <td>8.77192</td>\n","    </tr>\n","    <tr>\n","      <th>830</th>\n","      <td>2022-04-12</td>\n","      <td>8.77192</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>831 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6c0eefa-b27b-49ea-ad64-00813df4b555')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a6c0eefa-b27b-49ea-ad64-00813df4b555 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a6c0eefa-b27b-49ea-ad64-00813df4b555');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df_json.reset_index(drop=True)\n","df_json.set_index(\"Date\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"TRZUqDyCFZVS","executionInfo":{"status":"ok","timestamp":1649892822415,"user_tz":-540,"elapsed":4,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"42ccc844-75b0-4494-c910-0270b107d023"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               Count\n","Date                \n","2020-01-01  35.08771\n","2020-01-02  35.08771\n","2020-01-03  17.54385\n","2020-01-04  26.31578\n","2020-01-05  14.03508\n","...              ...\n","2022-04-08   7.01754\n","2022-04-09  14.03508\n","2022-04-10  10.52631\n","2022-04-11   8.77192\n","2022-04-12   8.77192\n","\n","[831 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-cae80035-b45b-40a9-a42f-13d003dd9c4c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Count</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2020-01-01</th>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-02</th>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-03</th>\n","      <td>17.54385</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-04</th>\n","      <td>26.31578</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-05</th>\n","      <td>14.03508</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-08</th>\n","      <td>7.01754</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-09</th>\n","      <td>14.03508</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-10</th>\n","      <td>10.52631</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-11</th>\n","      <td>8.77192</td>\n","    </tr>\n","    <tr>\n","      <th>2022-04-12</th>\n","      <td>8.77192</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>831 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cae80035-b45b-40a9-a42f-13d003dd9c4c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cae80035-b45b-40a9-a42f-13d003dd9c4c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cae80035-b45b-40a9-a42f-13d003dd9c4c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#Please refer to the section of \"Merging asof\" in https://pandas.pydata.org/docs/user_guide/merging.html\n","df_all = pd.merge_asof(df, df_json, on=\"Date\", by=\"Date\")"],"metadata":{"id":"qWrzE61AHwLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"16PpbyrlGZ7l","executionInfo":{"status":"ok","timestamp":1649892825638,"user_tz":-540,"elapsed":5,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"f9006d93-3b55-42d1-f471-9bffe7acbf60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Date    Open    High     Low   Close  Volume    Change     Count\n","0   2020-01-02  542000  545000  539000  541000   40246  0.000000  35.08771\n","1   2020-01-03  547000  568000  542000  565000  112404  0.044362  17.54385\n","2   2020-01-06  562000  587000  562000  579000  107006  0.024779  21.05263\n","3   2020-01-07  583000  596000  574000  594000   84378  0.025907   7.01754\n","4   2020-01-08  587000  604000  584000  604000  109267  0.016835  36.84210\n","..         ...     ...     ...     ...     ...     ...       ...       ...\n","558 2022-04-06  475000  483500  469000  474000   96750 -0.012500   3.50877\n","559 2022-04-07  469000  471500  462000  462000  103079 -0.025316   5.26315\n","560 2022-04-08  462500  466500  453500  458000   87055 -0.008658   7.01754\n","561 2022-04-11  450500  459000  449000  453500   59322 -0.009825   8.77192\n","562 2022-04-12  452000  461500  446500  458000  100684  0.009923   8.77192\n","\n","[563 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-b46aef6a-4f6b-454a-9d54-b0ab9d474ecd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>Change</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-02</td>\n","      <td>542000</td>\n","      <td>545000</td>\n","      <td>539000</td>\n","      <td>541000</td>\n","      <td>40246</td>\n","      <td>0.000000</td>\n","      <td>35.08771</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-03</td>\n","      <td>547000</td>\n","      <td>568000</td>\n","      <td>542000</td>\n","      <td>565000</td>\n","      <td>112404</td>\n","      <td>0.044362</td>\n","      <td>17.54385</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-06</td>\n","      <td>562000</td>\n","      <td>587000</td>\n","      <td>562000</td>\n","      <td>579000</td>\n","      <td>107006</td>\n","      <td>0.024779</td>\n","      <td>21.05263</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2020-01-07</td>\n","      <td>583000</td>\n","      <td>596000</td>\n","      <td>574000</td>\n","      <td>594000</td>\n","      <td>84378</td>\n","      <td>0.025907</td>\n","      <td>7.01754</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2020-01-08</td>\n","      <td>587000</td>\n","      <td>604000</td>\n","      <td>584000</td>\n","      <td>604000</td>\n","      <td>109267</td>\n","      <td>0.016835</td>\n","      <td>36.84210</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>558</th>\n","      <td>2022-04-06</td>\n","      <td>475000</td>\n","      <td>483500</td>\n","      <td>469000</td>\n","      <td>474000</td>\n","      <td>96750</td>\n","      <td>-0.012500</td>\n","      <td>3.50877</td>\n","    </tr>\n","    <tr>\n","      <th>559</th>\n","      <td>2022-04-07</td>\n","      <td>469000</td>\n","      <td>471500</td>\n","      <td>462000</td>\n","      <td>462000</td>\n","      <td>103079</td>\n","      <td>-0.025316</td>\n","      <td>5.26315</td>\n","    </tr>\n","    <tr>\n","      <th>560</th>\n","      <td>2022-04-08</td>\n","      <td>462500</td>\n","      <td>466500</td>\n","      <td>453500</td>\n","      <td>458000</td>\n","      <td>87055</td>\n","      <td>-0.008658</td>\n","      <td>7.01754</td>\n","    </tr>\n","    <tr>\n","      <th>561</th>\n","      <td>2022-04-11</td>\n","      <td>450500</td>\n","      <td>459000</td>\n","      <td>449000</td>\n","      <td>453500</td>\n","      <td>59322</td>\n","      <td>-0.009825</td>\n","      <td>8.77192</td>\n","    </tr>\n","    <tr>\n","      <th>562</th>\n","      <td>2022-04-12</td>\n","      <td>452000</td>\n","      <td>461500</td>\n","      <td>446500</td>\n","      <td>458000</td>\n","      <td>100684</td>\n","      <td>0.009923</td>\n","      <td>8.77192</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>563 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b46aef6a-4f6b-454a-9d54-b0ab9d474ecd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b46aef6a-4f6b-454a-9d54-b0ab9d474ecd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b46aef6a-4f6b-454a-9d54-b0ab9d474ecd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["## You need to visualized a relational graph\n","plt.figure(figsize=(20,10))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"MN6CLgl1KwPz","executionInfo":{"status":"ok","timestamp":1649892826708,"user_tz":-540,"elapsed":5,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"02f5a393-5175-479b-9bc9-4d53ff98f1f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 1440x720 with 0 Axes>"]},"metadata":{},"execution_count":19},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x720 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["df_all.any().isnull()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUC7xsPlSBeA","executionInfo":{"status":"ok","timestamp":1649892963698,"user_tz":-540,"elapsed":490,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"d2224fd4-c00e-452a-d7fd-18975b90c939"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date      False\n","Open      False\n","High      False\n","Low       False\n","Close     False\n","Volume    False\n","Change    False\n","Count     False\n","dtype: bool"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# scaling function for input data\n","def minmax_scaler(data):\n","    numerator = data - np.min(data, 0)\n","    denominator = np.max(data, 0) - np.min(data, 0)\n","    return numerator / (denominator + 1e-7)\n","\n","# scaling function for input data\n","def minmax_scaler(data):\n","    numerator = data - np.min(data, 0)\n","    denominator = np.max(data, 0) - np.min(data, 0)\n","    return numerator / (denominator + 1e-7)\n","\n","\n","# make dataset to train"],"metadata":{"id":"xOLOhyvpXhm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Define Model"],"metadata":{"id":"TNMOttK54rBV"}},{"cell_type":"code","source":["class LinearModel(torch.nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(LinearModel, self).__init__()\n","        self.linear_classifier = torch.nn.Linear(input_dim, output_dim, bias=True)\n","\n","    def forward(self, x):\n","        print(\"inX:\" ,x)\n","        print(\"inSquee\",x.unsqueeze(0))\n","        x = self.linear_classifier(x.unsqueeze(0))\n","        print(\"outX:\" ,x)\n","        return x"],"metadata":{"id":"gSpqndTU4Hcf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Define the loss function and the optimizer"],"metadata":{"id":"oixYOm_SJR0A"}},{"cell_type":"code","source":["input_dim = 1\n","output_dim = 1\n","learning_rate = 0.01\n","model = LinearModel(input_dim, output_dim)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","loss_function = torch.nn.MSELoss()"],"metadata":{"id":"fDMsIJ6r5Pfv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Define train function"],"metadata":{"id":"qoe4rEnxL7BY"}},{"cell_type":"code","source":["def train(train_x, train_y, loss_function, optimizer, model):\n","\n","  for idx in range(len(train_x)):\n","    model.train()\n","    optimizer.zero_grad()\n","    print(idx)\n","    print(train_x[idx])\n","    train_x_tensor = torch.tensor(train_x[idx]).float() #convert numpy to torch tensor\n","    train_y_tensor = torch.tensor(train_y[idx]).float()\n","    logit = model(train_x_tensor)\n","    print(\"the value of logit\", logit)\n","    loss = loss_function(logit, train_y_tensor)\n","    print(\"the value of loss\", loss)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","  return \"\""],"metadata":{"id":"7Cq43_T9KKgM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Training "],"metadata":{"id":"vSBoqT4TL4r8"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train_x, test_x, train_y, test_y = train_test_split(df_all[\"Count\"].to_numpy(),df_all[\"Change\"].to_numpy(), test_size=0.2)"],"metadata":{"id":"NAB9TuhoMBxa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = None\n","best_model = train(train_x, train_y, loss_function, optimizer, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oq7Hr22FMWd7","executionInfo":{"status":"ok","timestamp":1649894449959,"user_tz":-540,"elapsed":4748,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"36ef0df6-579a-4fe1-b4d4-7ca3f403ad2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([-22.3950], grad_fn=<AddBackward0>)\n","the value of logit tensor([-22.3950], grad_fn=<AddBackward0>)\n","the value of loss tensor(501.4857, grad_fn=<MseLossBackward0>)\n","1\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([326.6846], grad_fn=<AddBackward0>)\n","the value of logit tensor([326.6846], grad_fn=<AddBackward0>)\n","the value of loss tensor(106734.4766, grad_fn=<MseLossBackward0>)\n","2\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([-5169.2607], grad_fn=<AddBackward0>)\n","the value of logit tensor([-5169.2607], grad_fn=<AddBackward0>)\n","the value of loss tensor(26721256., grad_fn=<MseLossBackward0>)\n","3\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([81163.5547], grad_fn=<AddBackward0>)\n","the value of logit tensor([81163.5547], grad_fn=<AddBackward0>)\n","the value of loss tensor(6.5875e+09, grad_fn=<MseLossBackward0>)\n","4\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([-1123865.1250], grad_fn=<AddBackward0>)\n","the value of logit tensor([-1123865.1250], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.2631e+12, grad_fn=<MseLossBackward0>)\n","5\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([5351250.5000], grad_fn=<AddBackward0>)\n","the value of logit tensor([5351250.5000], grad_fn=<AddBackward0>)\n","the value of loss tensor(2.8636e+13, grad_fn=<MseLossBackward0>)\n","6\n","57.89473\n","inX: tensor(57.8947)\n","inSquee tensor([57.8947])\n","outX: tensor([-35992360.], grad_fn=<AddBackward0>)\n","the value of logit tensor([-35992360.], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.2954e+15, grad_fn=<MseLossBackward0>)\n","7\n","43.85964\n","inX: tensor(43.8596)\n","inSquee tensor([43.8596])\n","outX: tensor([1.8013e+09], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.8013e+09], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.2447e+18, grad_fn=<MseLossBackward0>)\n","8\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([-2.9736e+10], grad_fn=<AddBackward0>)\n","the value of logit tensor([-2.9736e+10], grad_fn=<AddBackward0>)\n","the value of loss tensor(8.8423e+20, grad_fn=<MseLossBackward0>)\n","9\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([7.0300e+10], grad_fn=<AddBackward0>)\n","the value of logit "]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["tensor([7.0300e+10], grad_fn=<AddBackward0>)\n","the value of loss tensor(4.9420e+21, grad_fn=<MseLossBackward0>)\n","10\n","38.59649\n","inX: tensor(38.5965)\n","inSquee tensor([38.5965])\n","outX: tensor([1.9087e+09], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.9087e+09], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.6432e+18, grad_fn=<MseLossBackward0>)\n","11\n","100.0\n","inX: tensor(100.)\n","inSquee tensor([100.])\n","outX: tensor([-1.4109e+11], grad_fn=<AddBackward0>)\n","the value of logit tensor([-1.4109e+11], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.9905e+22, grad_fn=<MseLossBackward0>)\n","12\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([6.8981e+12], grad_fn=<AddBackward0>)\n","the value of logit tensor([6.8981e+12], grad_fn=<AddBackward0>)\n","the value of loss tensor(4.7583e+25, grad_fn=<MseLossBackward0>)\n","13\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([-5.4658e+13], grad_fn=<AddBackward0>)\n","the value of logit tensor([-5.4658e+13], grad_fn=<AddBackward0>)\n","the value of loss tensor(2.9875e+27, grad_fn=<MseLossBackward0>)\n","14\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([1.1373e+14], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.1373e+14], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.2935e+28, grad_fn=<MseLossBackward0>)\n","15\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([9.4319e+09], grad_fn=<AddBackward0>)\n","the value of logit tensor([9.4319e+09], grad_fn=<AddBackward0>)\n","the value of loss tensor(8.8962e+19, grad_fn=<MseLossBackward0>)\n","16\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([1.8358e+12], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.8358e+12], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.3701e+24, grad_fn=<MseLossBackward0>)\n","17\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([-2.5653e+13], grad_fn=<AddBackward0>)\n","the value of logit tensor([-2.5653e+13], grad_fn=<AddBackward0>)\n","the value of loss tensor(6.5807e+26, grad_fn=<MseLossBackward0>)\n","18\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([2.6400e+14], grad_fn=<AddBackward0>)\n","the value of logit tensor([2.6400e+14], grad_fn=<AddBackward0>)\n","the value of loss tensor(6.9694e+28, grad_fn=<MseLossBackward0>)\n","19\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([-3.2512e+15], grad_fn=<AddBackward0>)\n","the value of logit tensor([-3.2512e+15], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.0571e+31, grad_fn=<MseLossBackward0>)\n","20\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([1.9328e+16], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.9328e+16], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.7356e+32, grad_fn=<MseLossBackward0>)\n","21\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([-1.6036e+16], grad_fn=<AddBackward0>)\n","the value of logit tensor([-1.6036e+16], grad_fn=<AddBackward0>)\n","the value of loss tensor(2.5715e+32, grad_fn=<MseLossBackward0>)\n","22\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([1.8608e+14], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.8608e+14], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.4626e+28, grad_fn=<MseLossBackward0>)\n","23\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([-5.8218e+14], grad_fn=<AddBackward0>)\n","the value of logit tensor([-5.8218e+14], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.3893e+29, grad_fn=<MseLossBackward0>)\n","24\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([2.0316e+15], grad_fn=<AddBackward0>)\n","the value of logit tensor([2.0316e+15], grad_fn=<AddBackward0>)\n","the value of loss tensor(4.1272e+30, grad_fn=<MseLossBackward0>)\n","25\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([-9.3600e+15], grad_fn=<AddBackward0>)\n","the value of logit tensor([-9.3600e+15], grad_fn=<AddBackward0>)\n","the value of loss tensor(8.7609e+31, grad_fn=<MseLossBackward0>)\n","26\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([1.3656e+16], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.3656e+16], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.8649e+32, grad_fn=<MseLossBackward0>)\n","27\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([-2.5651e+16], grad_fn=<AddBackward0>)\n","the value of logit tensor([-2.5651e+16], grad_fn=<AddBackward0>)\n","the value of loss tensor(6.5796e+32, grad_fn=<MseLossBackward0>)\n","28\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([1.7778e+17], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.7778e+17], grad_fn=<AddBackward0>)\n","the value of loss tensor(3.1605e+34, grad_fn=<MseLossBackward0>)\n","29\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([-4.1327e+17], grad_fn=<AddBackward0>)\n","the value of logit tensor([-4.1327e+17], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.7079e+35, grad_fn=<MseLossBackward0>)\n","30\n","42.10526\n","inX: tensor(42.1053)\n","inSquee tensor([42.1053])\n","outX: tensor([3.6593e+18], grad_fn=<AddBackward0>)\n","the value of logit tensor([3.6593e+18], grad_fn=<AddBackward0>)\n","the value of loss tensor(1.3390e+37, grad_fn=<MseLossBackward0>)\n","31\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([-4.2099e+19], grad_fn=<AddBackward0>)\n","the value of logit tensor([-4.2099e+19], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","32\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([1.0912e+20], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.0912e+20], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","33\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([-6.3225e+20], grad_fn=<AddBackward0>)\n","the value of logit tensor([-6.3225e+20], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","34\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([2.2518e+21], grad_fn=<AddBackward0>)\n","the value of logit tensor([2.2518e+21], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","35\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([2.9453e+21], grad_fn=<AddBackward0>)\n","the value of logit tensor([2.9453e+21], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","36\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([-7.8971e+21], grad_fn=<AddBackward0>)\n","the value of logit tensor([-7.8971e+21], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","37\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([3.7233e+22], grad_fn=<AddBackward0>)\n","the value of logit tensor([3.7233e+22], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","38\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([-2.0508e+23], grad_fn=<AddBackward0>)\n","the value of logit tensor([-2.0508e+23], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","39\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([-5.6293e+21], grad_fn=<AddBackward0>)\n","the value of logit tensor([-5.6293e+21], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","40\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([8.6234e+22], grad_fn=<AddBackward0>)\n","the value of logit tensor([8.6234e+22], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","41\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([-5.4392e+23], grad_fn=<AddBackward0>)\n","the value of logit tensor([-5.4392e+23], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","42\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([1.6618e+24], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.6618e+24], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","43\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([-1.5690e+25], grad_fn=<AddBackward0>)\n","the value of logit tensor([-1.5690e+25], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","44\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([9.2289e+25], grad_fn=<AddBackward0>)\n","the value of logit tensor([9.2289e+25], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","45\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([-6.6811e+26], grad_fn=<AddBackward0>)\n","the value of logit tensor([-6.6811e+26], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","46\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([1.0047e+28], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.0047e+28], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","47\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([-1.1242e+29], grad_fn=<AddBackward0>)\n","the value of logit tensor([-1.1242e+29], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","48\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([5.8184e+29], grad_fn=<AddBackward0>)\n","the value of logit tensor([5.8184e+29], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","49\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([-9.1013e+29], grad_fn=<AddBackward0>)\n","the value of logit tensor([-9.1013e+29], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","50\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([-2.1051e+30], grad_fn=<AddBackward0>)\n","the value of logit tensor([-2.1051e+30], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","51\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([5.8745e+30], grad_fn=<AddBackward0>)\n","the value of logit tensor([5.8745e+30], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","52\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([7.6409e+30], grad_fn=<AddBackward0>)\n","the value of logit tensor([7.6409e+30], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","53\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([-4.4118e+31], grad_fn=<AddBackward0>)\n","the value of logit tensor([-4.4118e+31], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","54\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([4.7959e+32], grad_fn=<AddBackward0>)\n","the value of logit tensor([4.7959e+32], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","55\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([-6.5834e+33], grad_fn=<AddBackward0>)\n","the value of logit tensor([-6.5834e+33], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","56\n","3.50877\n","inX: tensor(3.5088)\n","inSquee tensor([3.5088])\n","outX: tensor([1.2269e+34], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.2269e+34], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","57\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([4.5504e+34], grad_fn=<AddBackward0>)\n","the value of logit tensor([4.5504e+34], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","58\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([-2.5897e+35], grad_fn=<AddBackward0>)\n","the value of logit tensor([-2.5897e+35], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","59\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([1.6751e+36], grad_fn=<AddBackward0>)\n","the value of logit tensor([1.6751e+36], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","60\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([-7.8882e+36], grad_fn=<AddBackward0>)\n","the value of logit tensor([-7.8882e+36], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","61\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([3.7858e+37], grad_fn=<AddBackward0>)\n","the value of logit tensor([3.7858e+37], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","62\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([-inf], grad_fn=<AddBackward0>)\n","the value of logit tensor([-inf], grad_fn=<AddBackward0>)\n","the value of loss tensor(inf, grad_fn=<MseLossBackward0>)\n","63\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","64\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","65\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","66\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","67\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","68\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","69\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","70\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","71\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","72\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","73\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","74\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","75\n","3.50877\n","inX: tensor(3.5088)\n","inSquee tensor([3.5088])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","76\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","77\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","78\n","3.50877\n","inX: tensor(3.5088)\n","inSquee tensor([3.5088])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","79\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","80\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","81\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","82\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","83\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","84\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","85\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","86\n","nan\n","inX: tensor(nan)\n","inSquee tensor([nan])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","87\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","88\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","89\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","90\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","91\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","92\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","93\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","94\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","95\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","96\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","97\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","98\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","99\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","100\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","101\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","102\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","103\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","104\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","105\n","52.63157\n","inX: tensor(52.6316)\n","inSquee tensor([52.6316])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","106\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","107\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","108\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","109\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","110\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","111\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","112\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","113\n","3.50877\n","inX: tensor(3.5088)\n","inSquee tensor([3.5088])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","114\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","115\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","116\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","117\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","118\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","119\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","120\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","121\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","122\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","123\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","124\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","125\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","126\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","127\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","128\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","129\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","130\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","131\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","132\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","133\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","134\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","135\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","136\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","137\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","138\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","139\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","140\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","141\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","142\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","143\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","144\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","145\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","146\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","147\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","148\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","149\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","150\n","47.36842\n","inX: tensor(47.3684)\n","inSquee tensor([47.3684])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","151\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","152\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","153\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","154\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","155\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","156\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","157\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","158\n","38.59649\n","inX: tensor(38.5965)\n","inSquee tensor([38.5965])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","159\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","160\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","161\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","162\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","163\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","164\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","165\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","166\n","3.50877\n","inX: tensor(3.5088)\n","inSquee tensor([3.5088])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","167\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","168\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","169\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","170\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","171\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","172\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","173\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","174\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","175\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","176\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","177\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","178\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","179\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","180\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","181\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","182\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","183\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","184\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","185\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","186\n","38.59649\n","inX: tensor(38.5965)\n","inSquee tensor([38.5965])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","187\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","188\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","189\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","190\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","191\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","192\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","193\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","194\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","195\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","196\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","197\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","198\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","199\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","200\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","201\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","202\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","203\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","204\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","205\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","206\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","207\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","208\n","42.10526\n","inX: tensor(42.1053)\n","inSquee tensor([42.1053])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","209\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","210\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","211\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","212\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","213\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","214\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","215\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","216\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","217\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","218\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","219\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","220\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","221\n","50.87719\n","inX: tensor(50.8772)\n","inSquee tensor([50.8772])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","222\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","223\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","224\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","225\n","91.22807\n","inX: tensor(91.2281)\n","inSquee tensor([91.2281])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","226\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","227\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","228\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","229\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","230\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","231\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","232\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","233\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","234\n","52.63157\n","inX: tensor(52.6316)\n","inSquee tensor([52.6316])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","235\n","94.73684\n","inX: tensor(94.7368)\n","inSquee tensor([94.7368])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","236\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","237\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","238\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","239\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","240\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","241\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","242\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","243\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","244\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","245\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","246\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","247\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","248\n","49.1228\n","inX: tensor(49.1228)\n","inSquee tensor([49.1228])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","249\n","43.85964\n","inX: tensor(43.8596)\n","inSquee tensor([43.8596])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","250\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","251\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","252\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","253\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","254\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","255\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","256\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","257\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","258\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","259\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","260\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","261\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","262\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","263\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","264\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","265\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","266\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","267\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","268\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","269\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","270\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","271\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","272\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","273\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","274\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","275\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","276\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","277\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","278\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","279\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","280\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","281\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","282\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","283\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","284\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","285\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","286\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","287\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","288\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","289\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","290\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","291\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","292\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","293\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","294\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","295\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","296\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","297\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","298\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","299\n","73.68421\n","inX: tensor(73.6842)\n","inSquee tensor([73.6842])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","300\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","301\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","302\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","303\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","304\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","305\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","306\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","307\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","308\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","309\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","310\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","311\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","312\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","313\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","314\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","315\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","316\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","317\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","318\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","319\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","320\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","321\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","322\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","323\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","324\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","325\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","326\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","327\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","328\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","329\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","330\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","331\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","332\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","333\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","334\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","335\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","336\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","337\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","338\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","339\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","340\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","341\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","342\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","343\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","344\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","345\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","346\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","347\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","348\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","349\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","350\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","351\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","352\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","353\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","354\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","355\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","356\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","357\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","358\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","359\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","360\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","361\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","362\n","3.50877\n","inX: tensor(3.5088)\n","inSquee tensor([3.5088])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","363\n","35.08771\n","inX: tensor(35.0877)\n","inSquee tensor([35.0877])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","364\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","365\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","366\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","367\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","368\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","369\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","370\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","371\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","372\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","373\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","374\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","375\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","376\n","5.26315\n","inX: tensor(5.2632)\n","inSquee tensor([5.2632])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","377\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","378\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","379\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","380\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","381\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","382\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","383\n","42.10526\n","inX: tensor(42.1053)\n","inSquee tensor([42.1053])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","384\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","385\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","386\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","387\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","388\n","31.57894\n","inX: tensor(31.5789)\n","inSquee tensor([31.5789])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","389\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","390\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","391\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","392\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","393\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","394\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","395\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","396\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","397\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","398\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","399\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","400\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","401\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","402\n","28.07017\n","inX: tensor(28.0702)\n","inSquee tensor([28.0702])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","403\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","404\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","405\n","7.01754\n","inX: tensor(7.0175)\n","inSquee tensor([7.0175])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","406\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","407\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","408\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","409\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","410\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","411\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","412\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","413\n","43.85964\n","inX: tensor(43.8596)\n","inSquee tensor([43.8596])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","414\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","415\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","416\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","417\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","418\n","8.77192\n","inX: tensor(8.7719)\n","inSquee tensor([8.7719])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","419\n","12.2807\n","inX: tensor(12.2807)\n","inSquee tensor([12.2807])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","420\n","10.52631\n","inX: tensor(10.5263)\n","inSquee tensor([10.5263])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","421\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","422\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","423\n","19.29824\n","inX: tensor(19.2982)\n","inSquee tensor([19.2982])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","424\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","425\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","426\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","427\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","428\n","29.82456\n","inX: tensor(29.8246)\n","inSquee tensor([29.8246])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","429\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","430\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","431\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","432\n","40.35087\n","inX: tensor(40.3509)\n","inSquee tensor([40.3509])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","433\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","434\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","435\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","436\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","437\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","438\n","26.31578\n","inX: tensor(26.3158)\n","inSquee tensor([26.3158])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","439\n","21.05263\n","inX: tensor(21.0526)\n","inSquee tensor([21.0526])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","440\n","15.78947\n","inX: tensor(15.7895)\n","inSquee tensor([15.7895])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","441\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","442\n","24.5614\n","inX: tensor(24.5614)\n","inSquee tensor([24.5614])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","443\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","444\n","33.33333\n","inX: tensor(33.3333)\n","inSquee tensor([33.3333])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","445\n","38.59649\n","inX: tensor(38.5965)\n","inSquee tensor([38.5965])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","446\n","17.54385\n","inX: tensor(17.5438)\n","inSquee tensor([17.5438])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","447\n","22.80701\n","inX: tensor(22.8070)\n","inSquee tensor([22.8070])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","448\n","14.03508\n","inX: tensor(14.0351)\n","inSquee tensor([14.0351])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n","449\n","36.8421\n","inX: tensor(36.8421)\n","inSquee tensor([36.8421])\n","outX: tensor([nan], grad_fn=<AddBackward0>)\n","the value of logit tensor([nan], grad_fn=<AddBackward0>)\n","the value of loss tensor(nan, grad_fn=<MseLossBackward0>)\n"]}]},{"cell_type":"code","source":["#len(train_y)\n","len(train_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBGe9xxjXGOv","executionInfo":{"status":"ok","timestamp":1649894299539,"user_tz":-540,"elapsed":393,"user":{"displayName":"임경태컴퓨터공학과","userId":"12494854822250349419"}},"outputId":"b8ebb09c-2cf9-4fd5-e78a-8b9c1c6f1092"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["450"]},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","source":["# 6. Prediction"],"metadata":{"id":"4dcxR6HENDED"}},{"cell_type":"code","source":["def predict():\n","  return \"\""],"metadata":{"id":"tpeTGbdENCOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"xERZPzOuMXRG"},"execution_count":null,"outputs":[]}]}